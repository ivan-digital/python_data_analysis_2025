{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **DSPy - промпт инжиниринг - Автоматическая оптимизация промпта под кокретную задачу**\n",
        "\n",
        "Цель урока — научить слушателей создавать модульные (multi-stage) системы на базе LLM, а затем оптимизировать промпты (инструкции и примеры) таким образом, чтобы итоговая метрика качества (accuracy, retrieval score и т.п.) превышала вариант с ручным подбором текста промпта."
      ],
      "metadata": {
        "id": "APQel91MEkwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Введение: почему нужны многошаговые LM-программы и оптимизация промпта**\n",
        "\n",
        "Современные большие языковые модели (LLM) — например, GPT, Llama и пр. — отлично справляются с задачами на понимание и генерацию текста, однако:\n",
        "\n",
        "1. Часто «галлюцинируют» (выдумывают детали),\n",
        "2. Трудно оптимизируются для конкретного сложного пайплайна (например, когда задача требует нескольких шагов поиска, сводки, валидации).\n",
        "\n",
        "Во многих случаях подход «один запрос – один ответ» оказывается недостаточным. Вместо этого на практике мы строим многоступенчатые пайплайны (compound AI systems), в которых каждый шаг решает конкретную подзадачу:\n",
        "\n",
        "- Сформировать поисковый запрос,\n",
        "- Найти или извлечь релевантные документы,\n",
        "- Свести результаты,\n",
        "- Сгенерировать финальный ответ.\n",
        "\n",
        "Однако при создании подобной системы мы внезапно сталкиваемся с задачей:\n",
        "\n",
        "- **Как формулировать промпты для каждого шага?**\n",
        "- **Как эффективно улучшать (оптимизировать) эти промпты, не имея индивидуальной метрики на каждом шаге (только итоговая метрика)?**\n",
        "\n",
        "Тут на помощь приходит фреймворк DSPy (Declarative Self-improving Python), предлагающий:\n",
        "\n",
        "- Описывать каждый этап в терминах «сигнатур» (signature) — что модуль принимает на вход, что должен вернуть, какое описание задачи,\n",
        "- Задавать «адаптер» (adapter), который превращает описание сигнатуры в реальный запрос к LLM,\n",
        "- Запускать «оптимизатор» (optimizer), который автоматически подбирает лучшие инструкции и лучшие few-shot-примеры для каждого модуля, чтобы максимизировать заданную итоговую метрику,\n",
        "- При необходимости использовать «бутстрап» (bootstrap) — извлечение демо-примеров из успешных прогона модели, и т.д.\n"
      ],
      "metadata": {
        "id": "dR93zxMJFm1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ключевые компоненты в библиотеке DSPy**\n",
        "\n",
        "- **Сигнатура (Signature)**\n",
        "\n",
        "  Описывает основные поля: какие входы мы ждём (например, context, question), какой выход хотим получить (answer, search_query, и т.д.). Это, по сути, “core input → output behavior”.\n",
        "\n",
        "- **Предиктор (Predictor)**\n",
        "\n",
        "  Определяет, какую стратегию вывода (inference-time strategy) мы используем для сигнатуры: zero-shot, chain-of-thought, few-shot, агентный подход и т.д. Например, хотим ли мы, чтобы модель рассуждала пошагово (chain-of-thought) или сразу «выдавала результат».\n",
        "\n",
        "- **Адаптер (Adapter)**\n",
        "\n",
        "  Это «клей», который форматирует входы сигнатуры в текстовый запрос (prompt) к LLM и парсит её выход в более удобную структуру. Например, из (context, question) собирает строку: `“Given the context: {context}, please answer the following question: {question}”` и при получении ответа в виде текста — извлекает оттуда нужные куски.\n",
        "\n",
        "- **Метрики (Metrics) и проверки (Assertions)**\n",
        "\n",
        "  Механизмы определения качества (evaluation) и ограничений (constraints). Чаще всего у нас есть только одна итоговая метрика (например, Exact Match), но можно включать промежуточные проверки (assertions) для валидации формата или фактической корректности. Если ответ её не проходит — система может повторить запрос.\n",
        "\n",
        "- **Оптимизатор (Optimizer)**\n",
        "\n",
        "  Наконец, это те самые «строки, которые инструктируют (или веса, которые адаптируют) LLM» — но в более широком смысле это алгоритм, который ищет лучшие инструкции, примеры (few-shot), конфигурации шагов. Он пользуется метрикой (см. п.4), чтобы понять, какой вариант промпта лучше.\n"
      ],
      "metadata": {
        "id": "tHglhZAWMgB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Как обычно выглядит работа DSPy-оптимизаторов (Pipeline)**\n",
        "\n",
        "Если говорить именно о DSPy или схожих библиотеках, там процесс обычно строится так:\n",
        "\n",
        "1. Adapter генерирует начальный промпт для каждого модуля (исходя из сигнатуры и предиктора). Это даёт базовую версию системы.\n",
        "2. Мы генерируем примеры (примерно через rejection sampling) на тренировочном наборе: гоняем пайплайн и смотрим, где результат удовлетворяет метрике. Такие удачные траектории могут стать демо-примерами (бутстрап).\n",
        "3. Оптимизатор начинает менять инструкции или набор демо-примеров (few-shot), используя:\n",
        "  - Автоматический few-shot (dspy.BootstrapFewShotWithRandomSearch),\n",
        "  - Индукцию инструкций (dspy.MIPROv2), OPRO, либо другие методы.\n",
        "4. На каждом шаге оптимизатор пробует новые конфигурации, вызывает пайплайн на части тренировочного набора, измеряет метрику. По итогам он обновляет внутреннюю логику (например, в Bayesian TPE-стиле или через LLM, которые «учатся» на своих ошибках) и, наконец, выбирает лучшую конфигурацию промптов.\n",
        "\n",
        "Таким образом, один и тот же модуль (скажем, «GenerateSearchQuery») может итеративно улучшаться:\n",
        "\n",
        "- Чётче формулировать инструкцию,\n",
        "- Добавлять лучшие примеры,\n",
        "- Исключать «вредные» или неработающие куски,\n",
        "- Согласовываться с другим модулем «AnswerWithContext»."
      ],
      "metadata": {
        "id": "0qYnEHIyLk0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Мейнстрим-подходы к оптимизации промптов**\n",
        "\n",
        "Существуют разные типы оптимизаторов, опирающиеся на идеи из статьи “Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs” (Khattab et al., 2024) и смежных работ:\n",
        "\n",
        "1. **Bootstrap Random Search**\n",
        "\n",
        "  - Сначала запускаем модель, собираем «удачные» примеры (input-output) и используем их в качестве кандидатов для few-shot.\n",
        "  - Перебираем случайные наборы демо-примеров, выбирая те, что дают лучший score.\n",
        "\n",
        "\n",
        "2. **Module-Level OPRO (History-based)**\n",
        "\n",
        "  - Для каждого модуля ведём «историю» из [Instruction, Score].\n",
        "  - Пробуем сгенерировать новые инструкции, ориентируясь на прошлые лучшие.\n",
        "  - Небольшой минус: нет прямой оценки для каждого шага, поэтому результат может быть хуже, чем при согласованной оптимизации.\n",
        "\n",
        "3. **MIPRO / Bayesian Surrogate**\n",
        "\n",
        "  - Храним множество кандидатов (инструкций, демо-примеров) в некоем пуле.\n",
        "  - Используем байесовский оптимизатор (TPE, Optuna), чтобы предсказывать: «если я выберу такие-то инструкции и демо-примеры, скорее всего итоговая метрика будет такой-то».\n",
        "  - Выбираем наиболее перспективные комбинации, проверяем их реальным запуском.\n",
        "  - По результатам обновляем нашу модель и движемся дальше.\n",
        "Обычно показывает себя мощно, так как ищет глобально лучшие комбинации.\n",
        "\n",
        "4. **OPRO (Program-level / Module-level)**\n",
        "\n",
        "  - Модель сама «учится» на истории результатов: видит список «[instr, score], [instr, score], ...» и пытается написать новую лучшую инструкцию.\n",
        "  - Сложность: если пайплайн из нескольких модулей, нужно аккуратно решать задачу «credit assignment» (какой из шагов виноват в провале?)."
      ],
      "metadata": {
        "id": "2DWeoudMM6UU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Практическое задание**\n",
        "\n",
        "**Задача**: Реализовать (или продемонстрировать псевдокод) многошаговую систему «Вопрос–Ответ» (multi-hop QA) + применить автоматическую оптимизацию промптов для улучшения итоговой точности.\n",
        "\n",
        "1. **Система:**\n",
        "  - Модуль GenerateSearchQuery: принимает (question, context) и генерирует search_query.\n",
        "  - Функция поиска: имитирует поиск, возвращает релевантные документы.\n",
        "  - Модуль AnswerWithContext: собирает всё найденное и формирует финальный ответ.\n",
        "2. **Метрика:**\n",
        "  - Пусть это Exact Match с эталонным ответом (или любая своя).\n",
        "  - Имеем тренировочный набор из (вопрос, правильный ответ).\n",
        "3. **Оптимизация:**\n",
        "  - Возьмём, к примеру, MIPRO или Bootstrap Random Search.\n",
        "  - Соберём изначально демо-примеры (bootstrapping) или попробуем на голых инструкциях.\n",
        "  - Итерируем, пока не найдём хороший набор инструкций + few-shot примеров.\n",
        "4. **Проверить** на валидационном наборе, сравнить качество до и после."
      ],
      "metadata": {
        "id": "rvO7DUZLO5P1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Решение**\n",
        "\n",
        "Ниже приведён упрощённый пример. Он иллюстрирует, как мы можем описать модули (через сигнатуры) и как запустить DSPy-оптимизацию (например, с помощью MIPRO). Обратите внимание, что код предназначен в первую очередь для демонстрации — для полного запуска может потребоваться корректировка конкретных импортов, версий и т.д."
      ],
      "metadata": {
        "id": "UqrMJJwuXis-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import dspy\n",
        "\n",
        "#############################################\n",
        "# 1. Define Signatures for the Submodules   #\n",
        "#############################################\n",
        "\n",
        "class GenerateSearchQuery(dspy.Signature):\n",
        "    context: str = dspy.InputField()\n",
        "    question: str = dspy.InputField()\n",
        "    search_query: str = dspy.OutputField()\n",
        "\n",
        "class AnswerWithContext(dspy.Signature):\n",
        "    context: str = dspy.InputField()\n",
        "    question: str = dspy.InputField()\n",
        "    answer: str = dspy.OutputField()\n",
        "\n",
        "#############################################\n",
        "# 2. Define the MultiHopQA Module           #\n",
        "#############################################\n",
        "\n",
        "class MultiHopQA(dspy.Module):\n",
        "    \"\"\"\n",
        "    Модульная система, состоящая из двух подпроцессов:\n",
        "    1) Генерация поискового запроса,\n",
        "    2) Генерация итогового ответа.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_iterations=2):\n",
        "        super().__init__()\n",
        "        self.query_gen = dspy.ChainOfThought(GenerateSearchQuery)\n",
        "        self.answer_gen = dspy.ChainOfThought(AnswerWithContext)\n",
        "        self.max_iterations = max_iterations\n",
        "\n",
        "    def forward(self, question: str) -> str:\n",
        "        context_collected = \"\"\n",
        "        for _ in range(self.max_iterations):\n",
        "            # 1) Генерируем поисковый запрос\n",
        "            out_query = self.query_gen(\n",
        "                context=context_collected,\n",
        "                question=question\n",
        "            )\n",
        "            search_query = out_query[\"search_query\"]\n",
        "\n",
        "            # 2) Имитируем поиск (или обращение к реальному поисковому движку)\n",
        "            retrieved_docs = f\"Docs_for_{search_query}\"\n",
        "\n",
        "            # 3) Добавляем найденное в общий контекст\n",
        "            context_collected += f\"\\n{retrieved_docs}\"\n",
        "\n",
        "        # 4) Генерируем финальный ответ\n",
        "        out_ans = self.answer_gen(\n",
        "            context=context_collected,\n",
        "            question=question\n",
        "        )\n",
        "        final_answer = out_ans[\"answer\"]\n",
        "        return final_answer\n",
        "\n",
        "#############################################\n",
        "# 3. Prepare Data and Metric (Exact Match)  #\n",
        "#############################################\n",
        "\n",
        "train_data = [\n",
        "    {\n",
        "        \"input\": \"Кто написал роман 'Мастер и Маргарита'?\",\n",
        "        \"label\": \"Михаил Булгаков\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Какое уравнение открыл французский математик Жозеф Лиувилль?\",\n",
        "        \"label\": \"Уравнение Лиувилля (Liouville's equation)\"\n",
        "    },\n",
        "    # ... можно добавить больше примеров\n",
        "]\n",
        "\n",
        "def exact_match(prediction: str, reference: str) -> float:\n",
        "    pred = prediction.strip().lower()\n",
        "    ref = reference.strip().lower()\n",
        "    return 1.0 if ref in pred else 0.0\n",
        "\n",
        "def my_metric_fn(outputs, references) -> float:\n",
        "    scores = []\n",
        "    for pred, ref in zip(outputs, references):\n",
        "        scores.append(exact_match(pred, ref))\n",
        "    return sum(scores) / len(scores)\n",
        "\n",
        "#############################################\n",
        "# 4. Run the Optimizer (using MIPROv2)       #\n",
        "#############################################\n",
        "\n",
        "pipeline = MultiHopQA(max_iterations=2)\n",
        "\n",
        "# Функция для загрузки обучающих данных\n",
        "def data_loader_fn():\n",
        "    inputs = [item[\"input\"] for item in train_data]\n",
        "    references = [item[\"label\"] for item in train_data]\n",
        "    return inputs, references\n",
        "\n",
        "# Supply the required metric during instantiation.\n",
        "optimizer = dspy.MIPROv2(metric=my_metric_fn)\n",
        "\n",
        "# Use the compile method instead of optimize; pass the trainset directly.\n",
        "trainset = data_loader_fn()\n",
        "best_pipeline = optimizer.compile(pipeline, trainset=trainset, minibatch_size=1)\n",
        "\n",
        "#############################################\n",
        "# 5. Test the Final System                 #\n",
        "#############################################\n",
        "\n",
        "test_questions = [\n",
        "    \"Кто написал роман 'Мастер и Маргарита'?\",\n",
        "    \"Каково основное уравнение Лиувилля?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    ans = best_pipeline(q)\n",
        "    print(f\"Вопрос: {q}\\nОтвет: {ans}\\n---\")"
      ],
      "metadata": {
        "id": "rTqzLanrY5Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для предшествующего кода нужно еще сконфигурировать языковую модель."
      ],
      "metadata": {
        "id": "rkSaV7bcgYWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код реализует модульную систему для ответа на вопросы:\n",
        "\n",
        "Два шага:\n",
        "- Генерируется поисковой запрос на основе вопроса и текущего контекста.\n",
        "- После имитации поиска найденные данные добавляются к контексту, на основе которого формируется окончательный ответ.\n",
        "\n",
        "Обучение:\n",
        "- Система обучается с использованием оптимизатора dspy.MIPROv2 и метрики точного совпадения на тренировочных данных.\n",
        "\n",
        "Тестирование:\n",
        "- После обучения система отвечает на тестовые вопросы, используя накопленный контекст."
      ],
      "metadata": {
        "id": "MxO-GWcZY-t_"
      }
    }
  ]
}